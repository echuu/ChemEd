# omit entries with missing school; at this point, we should have 1170 x 50
d = d %>% filter(school %in% school_names)
# merge UNTB and UNTW schools into UNT
d[d$school == "UNTB" | d$school == "UNTW",]$school = "UNT"
hrs = d$hrs
dim(d)
View(d)
d = d[,1:33] # omit columns with common questions for this analysis
# write to file to do intermediate (manual) cleaning
write.csv(d, "must_partial_clean.csv", row.names = FALSE)
d = read.csv("must_partial_clean.csv") # 1073 x 32
# create pass indicator variable
d = d %>% mutate(pass = (course > MIN_PASS) + 0) # indicator for pass/fail
# check the class variable (4 outcomes)
d %>% select(class) %>% table
# check ethnicity variable (Asian, Black, Hispanic, Mixed, Other, White)
d %>% select(ethnic) %>% table
d$ethnic = as.factor(d$ethnic)
# gender: 0/female 642, 1/male 454, -1/missing 9
table(d$gender)
d$gender[is.na(d$gender)] = -1
d$gender = as.character(d$gender)
d$gender = as.factor(d$gender)
# major:
# STEM                    : 494
# medical                 : 469
# dual (stem + non-stem)  :  28
# other                   :  82
# stem students
stem  = c("a", "a. Eng", "a. Math", "a.Sci", "a. Sci", "a. Sci,Math",
"a. Sci, Tech", "a. Sc/Math", "a. Tech", "a. Tech,Eng",
"a. Tech,Math", "STEM", "a. Sci,Tech", "MATH")
# medical students
med   = c("b", "c + b", "SCI: c, b & b",
"SCI: c-b; b: ALL", "a. Sci+c")
# stem + non-stem
dual  = c("a. Sci & b", "b+a. Eng", "d", "STEM & b", "SCI: T&E; b")
# other students, blanks
other = c("", " ", "c", "Other", "C")
# length(stem) + length(med) + length(dual) + length(other)
d$major = as.character(d$major)
d$major[d$major %in% stem]  = "stem"
d$major[d$major %in% med]   = "med"
d$major[d$major %in% dual]  = "dual"
d$major[d$major %in% other] = "other"
table(d$major)
d$major = as.factor(d$major)
# parents: N (321), Y (766), Other (20)
table(d$parent)
# parents: N (321), Y (766), Other (20)
sum(table(d$parent))
sum(is.na(d$parent))
str(d$parent)
# grands: N (512), Y (446), Other (149)
table(d$grands)
# grands: N (512), Y (446), Other (149)
table(d$grand)
sum(is.na(d$grand))
str(d$grand)
# parents: N (321), Y (766), Other (20)
table(d$parent)
# grands: N (512), Y (446), Other (149)
table(d$grand)
# version
str(d$ver)
d$ver = as.factor(d$ver) # factor: levels 78, 87
table(d$ver)
table(d$emp_off)
table(d$emp_on)
d = read.csv("must_final.csv")
## GLOBAL VARS
n = nrow(d) # number of observations
school_names = c("ACUP", "TAMSA", "TAMU", "TSU", "UNTB", "UNTW", "UTXW")
MIN_PASS = 70 # lowest passing course score
################# ---- reformat school variable ---- ########################
# names(d)[1] = "school"
## remove the suffixes of each of the school so to extract 4-5 letter abbrev
id      = as.character(d[,1])
id_inst = character(n)
for(i in 1:n) {
n_char <- nchar(id[i])
id_inst[i] <- substr(id[i], 1, n_char - 3) # abbreviate schools
}
## Store just the 7 institution identifiers.
for (s in school_names) {
id_inst[grep(s, id_inst)] = s
}
## note that the number of observations from each school is different
## when we split into train/test sets, take equal proportions from each school
## so that we do not completely leave out a school
table(id_inst) # 7 schools identified by 4-5 letter codes -- 1073 total
# replace the existing school column with the newly encoded school IDs
d = d %>% mutate(school = id_inst)
# omit entries with missing school; at this point, we should have 1170 x 50
d = d %>% filter(school %in% school_names)
# merge UNTB and UNTW schools into UNT
d[d$school == "UNTB" | d$school == "UNTW",]$school = "UNT"
hrs = d$hrs
d = d[,1:33] # omit columns with common questions for this analysis
# write to file to do intermediate (manual) cleaning
write.csv(d, "must_partial_clean.csv", row.names = FALSE)
### -------------------------------------------------------------------------
# read in edited must_partial_clean.csv
d = read.csv("must_partial_clean.csv") # 1073 x 32
# create pass indicator variable
d = d %>% mutate(pass = (course > MIN_PASS) + 0) # indicator for pass/fail
# check the class variable (4 outcomes)
d %>% select(class) %>% table
# check ethnicity variable (Asian, Black, Hispanic, Mixed, Other, White)
d %>% select(ethnic) %>% table
d$ethnic = as.factor(d$ethnic)
# gender: 0/female 642, 1/male 454, -1/missing 9
table(d$gender)
d$gender[is.na(d$gender)] = -1
d$gender = as.character(d$gender)
d$gender = as.factor(d$gender)
# major:
# STEM                    : 494
# medical                 : 469
# dual (stem + non-stem)  :  28
# other                   :  82
# stem students
stem  = c("a", "a. Eng", "a. Math", "a.Sci", "a. Sci", "a. Sci,Math",
"a. Sci, Tech", "a. Sc/Math", "a. Tech", "a. Tech,Eng",
"a. Tech,Math", "STEM", "a. Sci,Tech", "MATH")
# medical students
med   = c("b", "c + b", "SCI: c, b & b",
"SCI: c-b; b: ALL", "a. Sci+c")
# stem + non-stem
dual  = c("a. Sci & b", "b+a. Eng", "d", "STEM & b", "SCI: T&E; b")
# other students, blanks
other = c("", " ", "c", "Other", "C")
# length(stem) + length(med) + length(dual) + length(other)
d$major = as.character(d$major)
d$major[d$major %in% stem]  = "stem"
d$major[d$major %in% med]   = "med"
d$major[d$major %in% dual]  = "dual"
d$major[d$major %in% other] = "other"
table(d$major)
d$major = as.factor(d$major)
# parents: N (305), Y (751), DK (17)
table(d$parent)
sum(is.na(d$parent))
str(d$parent)  # should be encoded as factor
# grands: N (491), Y (437), Other (145)
table(d$grand)
sum(is.na(d$grand))
str(d$grand)  # should be encoded as factor
table(d$emp_off)
table(d$emp_on)
str(d$emp_on)
str(d$emp_off)
# properly encode d$hrs variable
table(d$hrs)
str(d$hrs)
# version
str(d$ver)
d$ver = as.factor(d$ver) # factor: levels 78, 87
# check that all must questions encoded all values should be 1073
colSums(apply(d[,12:31], 2, table))
# create question categories
d = d %>% mutate(old_must = must - MQ6 - MQ16 - MQ17 - MQ18)
d = d %>% mutate(mult    = MQ1  +  MQ2  + MQ3,
div     = MQ4  +  MQ6  + MQ7  + MQ8  + MQ16,
frac    = MQ9  +  MQ10 + MQ17 + MQ18,
log_exp = MQ5  +  MQ12 + MQ13 + MQ14 + MQ15,
symb    = MQ11 +  MQ19 + MQ20)
rows_NA = d[rowSums(is.na(d)) > 0,]
View(rows_NA)
dim(rows_NA)
View(d)
dim9d
dim(d)
str(d)
# final dimensions to write to file: 1073 x 40
write.csv(d, "must.csv", row.names = FALSE)
# check to make sure gender, MQ's are factors before begin modeling
test_read = read.csv("must.csv")
View(test_read)
dim(test_read)
# modeling.R
library(glmnet)
# setwd("~/ChemEd/revisions")              # linux machine path
setwd("C:/Users/chuu/ChemEd/revisions")    # windows machine path
# source("/home/eric/ChemEd/paper_2/misc.R")    # linux machine path to misc.R
source("C:/Users/chuu/ChemEd/paper_2/misc.R") # windows machine path to misc.R
library(glmnet)
# setwd("~/ChemEd/revisions/data_cleaning")            # linux machine path
setwd("C:/Users/chuu/ChemEd/revisions/data_cleaning")  # windows machine path
# source("/home/eric/ChemEd/paper_2/misc.R")   # linux machine path to misc.R
source("C:/Users/chuu/ChemEd/paper_2/misc.R")  # windows machine path to misc.R
x0 = read.csv("must.csv")  # must.csv is the final cleaned data (1073 x 40)
# global vars
MUST_q = paste(rep("MQ", 20), 1:20, sep = "")  # 20 MUST questions
# ensure that each question is encoded as a factor
indicator_vars = c("gender", "version", "pass", MUST_q)
x0[,indicator_vars] = lapply(x0[,indicator_vars], as.factor)
# ensure that each question is encoded as a factor
indicator_vars = c("gender", "ver", "pass", MUST_q)
x0[,indicator_vars] = lapply(x0[,indicator_vars], as.factor)
str(x0) # only numeric variables: must, old_must, 5 categories, course average
## generate train/test set: seed = 30
train_test = generateTrainTest(x0, seed = 30)
x_train = train_test[[1]]   # 741 x 37
x_test  = train_test[[2]]   # 366 x 37
# questions not included in the old MUST exam
new_qs = c("MQ6", "MQ16", "MQ17", "MQ18")
cats   = c("mult", "div", "frac", "log_exp", "symb") # category names
# (1a) course_old: course average ~ old must + . (741 x 10 training matrix)
vars_omit = c(MUST_q, cats, "pass", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 10
course_must16 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_must16)
getMSE(course_must16, x_test, x_test$course) # 139.3325
# (1b) course_new: course average ~ new must + . (741 x 10 training matrix)
vars_omit = c(MUST_q, cats, "pass", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 10
course_must20 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_must20)
must20_coeffs = summary(course_must20)$coefficients
getMSE(course_must20, x_test, x_test$course) # 136.437
vars_omit = c(cats, new_qs, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 25
course_ind16 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_ind16)
getMSE(course_ind16, x_test, x_test$course) # 141.5527
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 29
# (2b) course_ind20: course average ~ all 20 must questions (741 x 29 training)
vars_omit = c(cats, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 29
course_ind20 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_ind20)
getMSE(course_ind20, x_test, x_test$course) # 138.2524
# test for significance between the nested models
anova(course_ind16, course_ind20) # p = 0.02883 < 0.05 --> extra q's significant
## course_cat: course average ~ must question categories (682 x 18)
vars_omit = c(MUST_q, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 18
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 13
# (1a) course_old: course average ~ old must + . (741 x 10 training matrix)
vars_omit = c(MUST_q, cats, "pass", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 13
# (1b) course_new: course average ~ new must + . (718 x 10 training matrix)
vars_omit = c(MUST_q, cats, "pass", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 10
## (2a) course_ind16: course average ~ 16 must questions (741 x 25 training)
# omit the 4 questions included in the new MUST
vars_omit = c(cats, new_qs, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 741 x 28
## (2a) course_ind16: course average ~ 16 must questions (718 x 28 training)
# omit the 4 questions included in the new MUST
vars_omit = c(cats, new_qs, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 28
# (2b) course_ind20: course average ~ all 20 must questions (718 x 29 training)
vars_omit = c(cats, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 32
## course_cat: course average ~ must question categories (682 x 18)
vars_omit = c(MUST_q, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 18
course_cat = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_cat) # all cats but multiplication significant
course_cat_coeffs = summary(course_cat)$coefficients
getMSE(course_cat, x_test, x_test$course) # 93.93881
# (4) lasso: course average ~ individual must questions (682 x 33 training)
# see if the new questions are not zero'd out by lasso
vars_omit = c(cats, "pass", "must", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 33
# lasso requires model matrix set up in particular way:
xtrain_lasso = x_train[,!(names(x0) %in% vars_omit)]     # omit irrelevant vars
xtrain_lasso$course = NULL                               # omit response
xtest_lasso = x_test[,!(names(x0) %in% vars_omit)]       # omit irrelevant vars
xtest_lasso$course = NULL                                # omit response
## check: num of columns for xtrain_lasso, xtest_lasso should be same
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
y_train = x_train$course   # training response (682 x 1)
y_test  = x_test$course    # test response     (338 x 1)
length(y_train)
length(y_test)
# create model matrix compatible with glmnet(), one hot encoding for factors
xtrain_mat = model.matrix( ~ . - 1, xtrain_lasso) # 682 x 53
xtest_mat  = model.matrix( ~ . - 1, xtest_lasso)  # 338 x 53
dim(xtrain_mat)
dim(xtest_mat)
View(xtrain_mat)
set.seed(1)
course_lasso = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star0 = cv_course_lasso$lambda.min)    # optimal lambda: 0.3523135
# lasso model coefficients
coeffs_l0 = predict(course_lasso, type = 'coefficients', s = lambda_star0)
lasso_pred0  = predict(course_lasso, s = lambda_star0, newx = xtest_mat)
mean((lasso_pred0 - y_test)^2) # MSE: 93.22
# (5) lasso: course average ~ category sums
# see which categories are indicative of performance
vars_omit = c(MUST_q, "pass", "must", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 18
# lasso requires model matrix set up in particular way:
xtrain_lasso = x_train[,!(names(x0) %in% vars_omit)]   # omit irrelevant vars
xtrain_lasso$course = NULL                             # omit response
xtest_lasso = x_test[,!(names(x0) %in% vars_omit)]      # omit irrelevant vars
xtest_lasso$course = NULL                               # omit response
## check: num of columns for xtrain_lasso, xtest_lasso should be same
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
y_train = x_train$course   # training response (682 x 1)
y_test  = x_test$course    # test response     (338 x 1)
length(y_train)
length(y_test)
# create model matrix compatible with glmnet(), one hot encoding for factors
xtrain_mat = model.matrix( ~ . - 1, xtrain_lasso) # 718 x 53
xtest_mat  = model.matrix( ~ . - 1, xtest_lasso)  # 355 x 53
dim(xtrain_mat)
set.seed(1)
course_lasso_cats = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso_cats = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star1 = cv_course_lasso_cats$lambda.min)    # optimal lambda: 0.4409111
# lasso model coefficients
coeffs_l1 = predict(course_lasso_cats, type = 'coefficients', s = lambda_star1)
lasso_pred1  = predict(course_lasso_cats, s = lambda_star1, newx = xtest_mat)
mean((lasso_pred1 - y_test)^2) # MSE: 96.74401
# (6a) logistic: pass ~ old must + ...
vars_omit = c(MUST_q, cats, "course", "must")     # old
dim(x_train[,!(names(x0) %in% vars_omit)])        # 682 x 14 -- match w/ (1a)
vars_omit = c(MUST_q, cats, "course", "must")     # old
dim(x_train[,!(names(x0) %in% vars_omit)])        # 718 x 13 -- match w/ (1a)
names(x_train[,!(names(x0) %in% vars_omit)])      # 718 x 13
pf0 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf0)
# obtain train/test balanced/overall accuracy, confusion matrix
pf0_results = getClassResults(m = pf0, x_train = x_train, x_test = x_test)
pf0_results$test_balance   # test balanced accuracy :  0.6652015
pf0_results$test_overall   # test overall accuracy  :  0.7810651
pf0_results$conf_mat       # true values of pass/fail are given by column sums
# (6b) logistic: pass ~ new must + ...
vars_omit = c(MUST_q, cats, "course", "old_must") # new
dim(x_train[,!(names(x0) %in% vars_omit)])        # 718 x 14 -- match w/ (1b)
names(x_train[,!(names(x0) %in% vars_omit)])      # 718 x 14
pf1 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf1)
# obtain train/test balanced/overall accuracy, confusion matrix
pf1_results = getClassResults(m = pf1, x_train = x_train, x_test = x_test)
pf1_results$test_balance   # test balanced accuracy :  0.6622711
pf1_results$test_overall   # test overall accuracy  :  0.7573964
pf1_results$conf_mat       # true values of pass/fail are given by column sums
# (7a) class_indic16: pass ~ 16 old MUST questions + ...
vars_omit = c(cats, new_qs, "course", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 29 -- match with (2a)
pf2 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf2)
pf2_results = getClassResults(m = pf2, x_train = x_train, x_test = x_test)
pf2_results$test_balance   # test balanced accuracy :  0.6186813
pf2_results$test_overall   # test overall accuracy  :  0.7721893
pf2_results$conf_mat       # true values of pass/fail are given by column sums
# (7b) class_indic20: pass ~ 20 old MUST questions + ...
vars_omit = c(cats, "course", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 33 -- match with (2b)
names(x_train[,!(names(x0) %in% vars_omit)])
pf3 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf3)
# obtain train/test balanced/overall accuracy, confusion matrix
pf3_results = getClassResults(m = pf3, x_train = x_train, x_test = x_test)
pf3_results$test_balance   # test balanced accuracy :  0.6084249
pf3_results$test_overall   # test overall accuracy  :  0.7840237
pf3_results$conf_mat       # true values of pass/fail are given by column sums
# (8) class_cat: pass ~ category sums
# class_cat
vars_omit = c(MUST_q, "course", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 18 -- match with (3)
pf4 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf4)
pf4_results = getClassResults(m = pf4, x_train = x_train, x_test = x_test)
pf4_results$test_balance   # test balanced accuracy :  0.6750916
pf4_results$test_overall   # test overall accuracy  :  0.7781065
## generate train/test set: seed = 30
train_test = generateTrainTest(x0, seed = 30)
x_train = train_test[[1]]   # 718 x 40
x_test  = train_test[[2]]   # 355 x 40
#### ------    regression for modeling course average old vs. new   ------- ####
# questions not included in the old MUST exam
new_qs = c("MQ6", "MQ16", "MQ17", "MQ18")
cats   = c("mult", "div", "frac", "log_exp", "symb") # category names
# (1) model using the total must score of old vs. new
# (1a) course_old: course average ~ old must + . (718 x 13 training matrix)
vars_omit = c(MUST_q, cats, "pass", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 13
course_must16 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_must16)
must16_coeffs = summary(course_must16)$coefficients
getMSE(course_must16, x_test, x_test$course) # 112.4562
vars_omit = c(MUST_q, cats, "pass", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 13
course_must20 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_must20)
must20_coeffs = summary(course_must20)$coefficients
getMSE(course_must20, x_test, x_test$course) # 110.3085
must16_coeffs
write.csv(must16_coeffs, "1a_coeffs.csv")
View(read.csv("1a_coeffs.csv"))
vars_omit = c(MUST_q, cats, "pass", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 13
course_must20 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_must20)
must20_coeffs = summary(course_must20)$coefficients
getMSE(course_must20, x_test, x_test$course) # 110.3085
write.csv(must20_coeffs, "1a_coeffs.csv")
write.csv(must16_coeffs, "1a_coeffs.csv")
write.csv(must20_coeffs, "1b_coeffs.csv")
write.csv(must16_coeffs, "model_coeffs/1a_coeffs.csv")
write.csv(must20_coeffs, "model_coeffs/1b_coeffs.csv")
vars_omit = c(cats, new_qs, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 28
course_ind16 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_ind16)
course_ind16_coeffs = summary(course_ind16)$coefficients
getMSE(course_ind16, x_test, x_test$course) # 108.3177
write.csv(must20_coeffs, "model_coeffs/2a_coeffs.csv")
# (2b) course_ind20: course average ~ all 20 must questions (718 x 29 training)
vars_omit = c(cats, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 32
course_ind20 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_ind20)
course_ind20_coeffs = summary(course_ind20)$coefficients
getMSE(course_ind20, x_test, x_test$course) # 106.9001
write.csv(must20_coeffs, "model_coeffs/2b_coeffs.csv")
# (3) model using category sums
## course_cat: course average ~ must question categories (718 x 17)
vars_omit = c(MUST_q, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 17
course_cat = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_cat) # all cats but division significant
course_cat_coeffs = summary(course_cat)$coefficients
getMSE(course_cat, x_test, x_test$course) # 108.7652
write.csv(course_ind16_coeffs, "model_coeffs/2a_coeffs.csv")
write.csv(course_ind20_coeffs, "model_coeffs/2b_coeffs.csv")
vars_omit = c(MUST_q, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 718 x 17
course_cat = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_cat) # all cats but division significant
course_cat_coeffs = summary(course_cat)$coefficients
getMSE(course_cat, x_test, x_test$course) # 108.7652
write.csv(course_cat_coeffs, "model_coeffs/3_coeffs.csv")
coeffs_l0
write.csv(coeffs_l0, "model_coeffs/4_coeffs.csv")
data.frame(coeffs_l0)
coeffs_l0[1]
unname(coeffs_l0)
data.frame(unname(coeffs_l0))
mean((lasso_pred0 - y_test)^2) # MSE: 107.9899
coeffs_l0
as.data.frame(as.matrix(coeffs_l0))
write.csv(as.data.frame(as.matrix(coeffs_l0)), "model_coeffs/4_coeffs.csv")
write.csv(as.data.frame(as.matrix(coeffs_l1)), "model_coeffs/5_coeffs.csv")
mean((lasso_pred1 - y_test)^2) # MSE: 109.4341
set.seed(1)
course_lasso_cats = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso_cats = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star1 = cv_course_lasso_cats$lambda.min)    # optimal lambda: 0.2955357
# lasso model coefficients
coeffs_l1 = predict(course_lasso_cats, type = 'coefficients', s = lambda_star1)
lasso_pred1  = predict(course_lasso_cats, s = lambda_star1, newx = xtest_mat)
mean((lasso_pred1 - y_test)^2) # MSE: 109.4341
coeffs_l1
(6a) logistic: pass ~ old must + ...
vars_omit = c(MUST_q, cats, "course", "must")     # old
dim(x_train[,!(names(x0) %in% vars_omit)])        # 718 x 13 -- match w/ (1a)
names(x_train[,!(names(x0) %in% vars_omit)])      # 718 x 13
pf0 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf0)
# obtain train/test balanced/overall accuracy, confusion matrix
pf0_results = getClassResults(m = pf0, x_train = x_train, x_test = x_test)
pf0_results$test_balance   # test balanced accuracy :  0.6675231
pf0_results$test_overall   # test overall accuracy  :  0.8028169
pf0_results$conf_mat       # true values of pass/fail are given by column sums
coeffs_6a = coef(pf0)
coeffs_6a
summary(pf0)$coefficients
coeffs_6a = summary(pf0)$coefficients
coeffs_6a
write.csv(as.data.frame(as.matrix(coeffs_6a)), "model_coeffs/6a_coeffs.csv")
summary(pf0)
coeffs_6b = summary(pf1)$coefficients
write.csv(as.data.frame(as.matrix(coeffs_6b)), "model_coeffs/6b_coeffs.csv")
summary(pf0)
summary(pf1)
summary(pf0)
coeffs_l1
coeffs_7a = summary(pf2)$coefficients
write.csv(coeffs_7a, "model_coeffs/7a_coeffs.csv")
coeffs_7b = summary(pf3)$coefficients
write.csv(coeffs_7b, "model_coeffs/7b_coeffs.csv")
coeffs_8 = summary(pf4)$coefficients
write.csv(coeffs_8, "model_coeffs/8_coeffs.csv")
coeffs_6b
summary(pf1)
summary(pf2)
summary(pf3)
summary(pf4)
summary(course_must16)
summary(course_must20)
summary(course_ind16)
summary(course_ind20)
summary(course_cat) # all cats but division significant
summary(pf0)
summary(pf1)
summary(pf2)
summary(pf3)
summary(pf4)
