course_ind20 = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_ind20)
course_ind20_coeffs = summary(course_ind20)$coefficients
getMSE(course_ind20, x_test, x_test$course) # 93.2738
# test for significance between the nested models
anova(course_ind16, course_ind20) # p = 0.02883 < 0.05 --> extra q's significant
#### ---   regression for modeling course average using question cats   --- ####
# (3) model using category sums
## course_cat: course average ~ must question categories (682 x 18)
vars_omit = c(MUST_q, "pass", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 18
course_cat = lm(course ~ ., x_train[,!(names(x0) %in% vars_omit)])
summary(course_cat) # all cats but multiplication significant
course_cat_coeffs = summary(course_cat)$coefficients
getMSE(course_cat, x_test, x_test$course) # 93.93881
#### -------    lasso reg for modeling course average old vs. new   ------- ####
# (4) lasso: course average ~ individual must questions (682 x 33 training)
# see if the new questions are not zero'd out by lasso
vars_omit = c(cats, "pass", "must", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 33
# lasso requires model matrix set up in particular way:
xtrain_lasso = x_train[,!(names(x0) %in% vars_omit)]   # omit irrelevant vars
xtrain_lasso$course = NULL                             # omit response
xtest_lasso = x_test[,!(names(x0) %in% vars_omit)]      # omit irrelevant vars
xtest_lasso$course = NULL                              # omit response
## check: num of columns for xtrain_lasso, xtest_lasso should be same
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
y_train = x_train$course   # training response (682 x 1)
y_test  = x_test$course    # test response     (338 x 1)
# create model matrix compatible with glmnet(), one hot encoding for factors
xtrain_mat = model.matrix( ~ . - 1, xtrain_lasso) # 682 x 53
xtest_mat  = model.matrix( ~ . - 1, xtest_lasso)  # 338 x 53
set.seed(1)
course_lasso = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star0 = cv_course_lasso$lambda.min)    # optimal lambda: 0.3523135
# lasso model coefficients
coeffs_l0 = predict(course_lasso, type = 'coefficients', s = lambda_star0)
lasso_pred0  = predict(course_lasso, s = lambda_star0, newx = xtest_mat)
mean((lasso_pred0 - y_test)^2) # MSE: 93.22
# (5) lasso: course average ~ category sums
# see which categories are indicative of performance
vars_omit = c(MUST_q, "pass", "must", "old_must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 18
# lasso requires model matrix set up in particular way:
xtrain_lasso = x_train[,!(names(x0) %in% vars_omit)]   # omit irrelevant vars
xtrain_lasso$course = NULL                             # omit response
xtest_lasso = x_test[,!(names(x0) %in% vars_omit)]      # omit irrelevant vars
xtest_lasso$course = NULL                               # omit response
## check: num of columns for xtrain_lasso, xtest_lasso should be same
ncol(xtrain_lasso) == ncol(xtest_lasso) # should print TRUE
y_train = x_train$course   # training response (682 x 1)
y_test  = x_test$course    # test response     (338 x 1)
# create model matrix compatible with glmnet(), one hot encoding for factors
xtrain_mat = model.matrix( ~ . - 1, xtrain_lasso) # 682 x 53
xtest_mat  = model.matrix( ~ . - 1, xtest_lasso)  # 338 x 53
set.seed(1)
course_lasso_cats = glmnet(x = xtrain_mat, y = y_train, alpha = 1)
cv_course_lasso_cats = cv.glmnet(x = xtrain_mat, y = y_train, alpha = 1)
(lambda_star1 = cv_course_lasso_cats$lambda.min)    # optimal lambda: 0.4409111
# lasso model coefficients
coeffs_l1 = predict(course_lasso_cats, type = 'coefficients', s = lambda_star1)
lasso_pred1  = predict(course_lasso_cats, s = lambda_star1, newx = xtest_mat)
mean((lasso_pred1 - y_test)^2) # MSE: 96.74401
#### ----    classification for modeling course average old vs. new   ----- ####
# (6) model using the total must score of old vs. new --------------------------
# (6a) logistic: pass ~ old must + ...
vars_omit = c(MUST_q, cats, "course", "must")     # old
dim(x_train[,!(names(x0) %in% vars_omit)])        # 682 x 14 -- match w/ (1a)
names(x_train[,!(names(x0) %in% vars_omit)])      # 682 x 14
pf0 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf0)
# obtain train/test balanced/overall accuracy, confusion matrix
pf0_results = getClassResults(m = pf0, x_train = x_train, x_test = x_test)
pf0_results$test_balance   # test balanced accuracy :  0.6652015
pf0_results$test_overall   # test overall accuracy  :  0.7810651
pf0_results$conf_mat       # true values of pass/fail are given by column sums
# (6b) logistic: pass ~ new must + ...
vars_omit = c(MUST_q, cats, "course", "old_must") # new
dim(x_train[,!(names(x0) %in% vars_omit)])        # 682 x 14 -- match w/ (1b)
names(x_train[,!(names(x0) %in% vars_omit)])      # 682 x 14
pf1 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf1)
# obtain train/test balanced/overall accuracy, confusion matrix
pf1_results = getClassResults(m = pf1, x_train = x_train, x_test = x_test)
pf1_results$test_balance   # test balanced accuracy :  0.6622711
pf1_results$test_overall   # test overall accuracy  :  0.7573964
pf1_results$conf_mat       # true values of pass/fail are given by column sums
# (7) pass ~ new/old must individual questions (omit category sums) ------------
# (7a) class_indic16: pass ~ 16 old MUST questions + ...
vars_omit = c(cats, new_qs, "course", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 29 -- match with (2a)
names(x_train[,!(names(x0) %in% vars_omit)])
pf2 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf2)
# obtain train/test balanced/overall accuracy, confusion matrix
pf2_results = getClassResults(m = pf2, x_train = x_train, x_test = x_test)
pf2_results$test_balance   # test balanced accuracy :  0.6186813
pf2_results$test_overall   # test overall accuracy  :  0.7721893
pf2_results$conf_mat       # true values of pass/fail are given by column sums
# (7b) class_indic20: pass ~ 20 old MUST questions + ...
vars_omit = c(cats, "course", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 33 -- match with (2b)
names(x_train[,!(names(x0) %in% vars_omit)])
pf3 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf3)
# obtain train/test balanced/overall accuracy, confusion matrix
pf3_results = getClassResults(m = pf3, x_train = x_train, x_test = x_test)
pf3_results$test_balance   # test balanced accuracy :  0.6084249
pf3_results$test_overall   # test overall accuracy  :  0.7840237
pf3_results$conf_mat       # true values of pass/fail are given by column sums
# (8) class_cat: pass ~ category sums
# class_cat
vars_omit = c(MUST_q, "course", "old_must", "must")
dim(x_train[,!(names(x0) %in% vars_omit)]) # 682 x 18 -- match with (3)
pf4 = glm(as.factor(pass) ~ ., family = 'binomial',
x_train[,!(names(x0) %in% vars_omit)])
summary(pf4)
# obtain train/test balanced/overall accuracy, confusion matrix
pf4_results = getClassResults(m = pf4, x_train = x_train, x_test = x_test)
pf4_results$test_balance   # test balanced accuracy :  0.6750916
pf4_results$test_overall   # test overall accuracy  :  0.7781065
pf4_results$conf_mat       # true values of pass/fail are given by column sums
# read in edited must_partial_clean.csv
d = read.csv("must_partial_clean.csv")
setwd("C:/Users/chuu/ChemEd/revisions/data_cleaning")
setwd("C:/Users/chuu/ChemEd/revisions/data_cleaning")
# read in edited must_partial_clean.csv
d = read.csv("must_partial_clean.csv")
View(d)
# remove rows without course average reported
sum(!is.na(d$course))
# remove rows without course average reported
d = d[!is.na(d$course),]
dim(d)
d = d %>% mutate(pass = (course > MIN_PASS) + 0) # indicator for pass/fail
# class
d %>% select(class) %>% table
d$class[d$class == "SO " ]
d$class[d$class == "SO " ] = "SO"
# class
d %>% select(class) %>% table
d$class[d$class == "SP" ]  = "SO"
d$class = droplevels(d$class)      # drop levels with no observations
# class
d %>% select(class) %>% table
length(table(d$ethnic))
table(d$ethnic)
mixed = c("White,Nat Am", "White,PI", "White, Asian", "White,AsianInd",
"White,Black", "White,Hisp", " White,NA",
"White, NA", "White,Asian", "White,Arab", "Mixed", "Hisp,White",
"Hisp,Arab", "Hisp,Asian", "Hisp,AsianInd", "Hisp,Black", "Hisp, NA",
"Hisp &White", "Black,White", "Black,Hisp", "Asian,White",
"Asian, PI")
sum(!(mixed %in% ethn_names)) # check for mis-spelled ethnicities
ethn_names = names(table(d$ethnic))
mixed = c("White,Nat Am", "White,PI", "White, Asian", "White,AsianInd",
"White,Black", "White,Hisp", " White,NA",
"White, NA", "White,Asian", "White,Arab", "Mixed", "Hisp,White",
"Hisp,Arab", "Hisp,Asian", "Hisp,AsianInd", "Hisp,Black", "Hisp, NA",
"Hisp &White", "Black,White", "Black,Hisp", "Asian,White",
"Asian, PI")
sum(!(mixed %in% ethn_names)) # check for mis-spelled ethnicities
d$ethnic[(d$ethnic %in% mixed)] = "Mixed"  # group Mixed
d$ethnic[d$ethnic == "Whte"] = "White"     # White mispelled
ethn_groups = c("Other", "Asian", "White", "Mixed", "Hisp", "Black")
d$ethnic[!(d$ethnic %in% ethn_groups)] = "Other"
table(d$ethnic)
d$ethnic = droplevels(d$ethnic)      # drop levels with no observations
table(d$ethnic)
sum(table(d$ethnic))
dim(d)
length(mixed)
# read in edited must_partial_clean.csv
d = read.csv("must_partial_clean.csv")
# remove rows without course average reported
d = d[!is.na(d$course),]   # 1107 x 34
##################### ---- add pass/fail variable ---- #########################
d = d %>% mutate(pass = (course > MIN_PASS) + 0) # indicator for pass/fail
#####################    process variable values    ############################
## Many of the variables contain values that are incorrectly inputted, creating
## extra factor levels. Here we manually go through and fix the inputs
# class (FR/)
d %>% select(class) %>% table
d$class[d$class == "SO " ] = "SO"
d$class[d$class == "SP" ]  = "SO"
d$class = droplevels(d$class)      # drop levels with no observations
## PB class variable ??? this makes no fucking sense
# ethnicity (Paper's Count // My Count), * indicates count discrepancy
# Asian:     78  //  78
# Black:     60  //  60
# Hispanic: 267  //  267
# Mixed:     85  //  86  *
# White:    493  //  492 *
# Other:     36  //  37  *
# Other (Arabic, Asian Indian, Native American, Pacific Islander, Pakistani)
# note: this new def of the group 'Other' differs slightly from part 1 analysis
length(table(d$ethnic))
table(d$ethnic)
d$ethnic = as.character(d$ethnic)
d$ethnic[(d$ethnic %in% mixed)] = "Mixed"  # group Mixed
d$ethnic[d$ethnic == "Whte"] = "White"     # White mispelled
table(d$ethnic)
ethn_groups = c("Other", "Asian", "White", "Mixed", "Hisp", "Black")
d$ethnic[!(d$ethnic %in% ethn_groups)] = "Other"
table(d$ethnic)
sum(table(d$ethnic))
# gender: 0 (female), 1 (male), -1 (missing)
table(d$gender)
d$gender[is.na(d$gender)] = -1
sum(is.na(d$gender)) # 10 missing values
d$gender[d$gender) == ""]
d$gender[d$gender == ""]
d$gender[d$gender == " "]
d$gender[d$gender == ""] = -1
d$gender[d$gender == " "] = -1
# gender: 0 (female), 1 (male), -1 (missing)
table(d$gender)
# gender: 0 (female), 1 (male), -1 (missing)
table(d$gender)
d = read.csv("must_partial_clean.csv")
# remove rows without course average reported
d = d[!is.na(d$course),]   # 1107 x 34
##################### ---- add pass/fail variable ---- #########################
d = d %>% mutate(pass = (course > MIN_PASS) + 0) # indicator for pass/fail
#####################    process variable values    ############################
## Many of the variables contain values that are incorrectly inputted, creating
## extra factor levels. Here we manually go through and fix the inputs
# class (FR/)
d %>% select(class) %>% table
d$class[d$class == "SO " ] = "SO"
d$class[d$class == "SP" ]  = "SO"
d$class = droplevels(d$class)      # drop levels with no observations
## PB class variable ???
# ethnicity (Paper's Count // My Count), * indicates count discrepancy
# Asian      :  80
# Black      :  70
# Hispanic   : 299
# Mixed      :  98
# White      :  41
# Other      : 519
# Other (Arabic, Asian Indian, Native American, Pacific Islander, Pakistani)
# note: this new def of the group 'Other' differs slightly from part 1 analysis
length(table(d$ethnic))
table(d$ethnic)
ethn_names = names(table(d$ethnic))
mixed = c("White,Nat Am", "White,PI", "White, Asian", "White,AsianInd",
"White,Black", "White,Hisp", " White,NA",
"White, NA", "White,Asian", "White,Arab", "Mixed", "Hisp,White",
"Hisp,Arab", "Hisp,Asian", "Hisp,AsianInd", "Hisp,Black", "Hisp, NA",
"Hisp &White", "Black,White", "Black,Hisp", "Asian,White",
"Asian, PI")
sum(!(mixed %in% ethn_names)) # check for mis-spelled ethnicities
d$ethnic = as.character(d$ethnic)
d$ethnic[(d$ethnic %in% mixed)] = "Mixed"  # group Mixed
d$ethnic[d$ethnic == "Whte"] = "White"     # White mispelled
ethn_groups = c("Other", "Asian", "White", "Mixed", "Hisp", "Black")
d$ethnic[!(d$ethnic %in% ethn_groups)] = "Other"
# gender: 0 (female), 1 (male), -1 (missing)
table(d$gender)
sum(table(d$gender))
str(table(d$gender))
d$gender = as.character(d$gender)
table(d$gender)
length(d$gender[d$gender == ""])
d$gender[d$gender == ""] = -1
# gender: 0 (female), 1 (male), -1 (missing)
table(d$gender)
length(d$gender[d$gender == "o"])
length(d$gender[d$gender == "O"])
d$gender[d$gender == "O"] = 0
# gender: 0 (female), 1 (male), -1 (missing)
table(d$gender)
d$gender = as.factor(d$gender)
# gender: 0 (female), 1 (male), -1 (missing)
table(d$gender)
table(d$parent)
d$parent = as.character(d$parent)
d$parent[d$parent == "n"] = "N"
d$parent[!(d$parent %in% c("N", "Y"))] = "Other"
d$parent = as.factor(d$parent)
# parents
table(d$parent)
d = read.csv("must_partial_clean.csv")
# remove rows without course average reported
d = d[!is.na(d$course),]   # 1107 x 34
##################### ---- add pass/fail variable ---- #########################
d = d %>% mutate(pass = (course > MIN_PASS) + 0) # indicator for pass/fail
#####################    process variable values    ############################
## Many of the variables contain values that are incorrectly inputted, creating
## extra factor levels. Here we manually go through and fix the inputs
# class (FR/)
d %>% select(class) %>% table
d$class[d$class == "SO " ] = "SO"
d$class[d$class == "SP" ]  = "SO"
d$class = droplevels(d$class)      # drop levels with no observations
## PB class variable ???
# ethnicity (Paper's Count // My Count), * indicates count discrepancy
# Asian      :  80
# Black      :  70
# Hispanic   : 299
# Mixed      :  98
# White      :  41
# Other      : 519
# Other (Arabic, Asian Indian, Native American, Pacific Islander, Pakistani)
# note: this new def of the group 'Other' differs slightly from part 1 analysis
length(table(d$ethnic))
table(d$ethnic)
ethn_names = names(table(d$ethnic))
mixed = c("White,Nat Am", "White,PI", "White, Asian", "White,AsianInd",
"White,Black", "White,Hisp", " White,NA",
"White, NA", "White,Asian", "White,Arab", "Mixed", "Hisp,White",
"Hisp,Arab", "Hisp,Asian", "Hisp,AsianInd", "Hisp,Black", "Hisp, NA",
"Hisp &White", "Black,White", "Black,Hisp", "Asian,White",
"Asian, PI")
sum(!(mixed %in% ethn_names)) # check for mis-spelled ethnicities
d$ethnic = as.character(d$ethnic)
d$ethnic[(d$ethnic %in% mixed)] = "Mixed"  # group Mixed
d$ethnic[d$ethnic == "Whte"] = "White"     # White mispelled
ethn_groups = c("Other", "Asian", "White", "Mixed", "Hisp", "Black")
d$ethnic[!(d$ethnic %in% ethn_groups)] = "Other"
# gender: 0/female 642, 1/male 454, -1/missing 11
table(d$gender)
d$gender = as.character(d$gender)
d$gender[d$gender == ""] = -1
d$gender[d$gender == "O"] = 0
d$gender = as.factor(d$gender)
# gender: 0/female 642, 1/male 454, -1/missing 11
table(d$gender)
# parents
table(d$parent)
d$parent = as.character(d$parent)
d$parent[d$parent == "n"] = "N"
d$parent[!(d$parent %in% c("N", "Y"))] = "Other"
d$parent = as.factor(d$parent)
# parents
table(d$parent)
# grands:
table(d$grand)
d$grand = as.character(d$grand)
d$grand[d$grand == "n"] = "N"
d$grand[d$grand == "N "] = "N"
# grands:
table(d$grand)
d$grand[!(d$grand %in% c("N", "Y"))] = "Other"
d$grand = as.factor(d$grand)
# grands:
table(d$grand)
# version
str(d$version)
d$version = as.factor(d$version) # factor: levels 78, 87
# version
str(d$version)
d = read.csv("must_partial_clean.csv")
# remove rows without course average reported
d = d[!is.na(d$course),]   # 1107 x 34
##################### ---- add pass/fail variable ---- #########################
d = d %>% mutate(pass = (course > MIN_PASS) + 0) # indicator for pass/fail
#####################    process variable values    ############################
## Many of the variables contain values that are incorrectly inputted, creating
## extra factor levels. Here we manually go through and fix the inputs
# class (FR/)
d %>% select(class) %>% table
d$class[d$class == "SO " ] = "SO"
d$class[d$class == "SP" ]  = "SO"
d$class = droplevels(d$class)      # drop levels with no observations
## PB class variable ???
# ethnicity (Paper's Count // My Count), * indicates count discrepancy
# Asian      :  80
# Black      :  70
# Hispanic   : 299
# Mixed      :  98
# White      :  41
# Other      : 519
# Other (Arabic, Asian Indian, Native American, Pacific Islander, Pakistani)
# note: this new def of the group 'Other' differs slightly from part 1 analysis
length(table(d$ethnic))
table(d$ethnic)
ethn_names = names(table(d$ethnic))
mixed = c("White,Nat Am", "White,PI", "White, Asian", "White,AsianInd",
"White,Black", "White,Hisp", " White,NA",
"White, NA", "White,Asian", "White,Arab", "Mixed", "Hisp,White",
"Hisp,Arab", "Hisp,Asian", "Hisp,AsianInd", "Hisp,Black", "Hisp, NA",
"Hisp &White", "Black,White", "Black,Hisp", "Asian,White",
"Asian, PI")
sum(!(mixed %in% ethn_names)) # check for mis-spelled ethnicities
d$ethnic = as.character(d$ethnic)
d$ethnic[(d$ethnic %in% mixed)] = "Mixed"  # group Mixed
d$ethnic[d$ethnic == "Whte"] = "White"     # White mispelled
ethn_groups = c("Other", "Asian", "White", "Mixed", "Hisp", "Black")
d$ethnic[!(d$ethnic %in% ethn_groups)] = "Other"
# gender: 0/female 642, 1/male 454, -1/missing 11
table(d$gender)
d$gender = as.character(d$gender)
d$gender[d$gender == ""] = -1
d$gender[d$gender == "O"] = 0
d$gender = as.factor(d$gender)
# parents: N (321), Y (766), Other (20)
table(d$parent)
names(d)
d$parent
dim(d)
# parents: N (321), Y (766), Other (20)
table(d$parents)
# parents: N (321), Y (766), Other (20)
table(d$parent)
# parents: N (321), Y (766), Other (20)
table(d$parents)
d$parents = as.character(d$parents)
d$parents[d$parents == "n"] = "N"
d$parents[!(d$parents %in% c("N", "Y"))] = "Other"
d$parents = as.factor(d$parents)
# grands: N (512), Y (446), Other (149)
table(d$grands)
d$grands = as.character(d$grands)
d$grands[d$grands == "n"] = "N"
d$grands[d$grands == "N "] = "N"
d$grands[!(d$grands %in% c("N", "Y"))] = "Other"
d$grands = as.factor(d$grands)
# version
str(d$version)
d$version = as.factor(d$version) # factor: levels 78, 87
# tx_hs
table(d$tx_hs)
# tx_hs --- too few No's
d$tx_hs = NULL
# emp_on:
table(d$emp_on)
d$emp_on = as.character(d$emp_on)
# emp_off:
table(d$emp_off)
# subset rows containing NA values:
rows_NA = d[rowSums(is.na(d)) > 0,] # rows are containing mostly variables that
# one of the MQ7 entries has a typo, making the entire column a factor
table(d$MQ7)
i = which(d$MQ7 == "`0")
d$MQ7[i] = 0
d$MQ7 = droplevels(d$MQ7)
d$MQ7 = as.numeric(as.character(d$MQ7))
table(d$MQ7)
?apply
apply(d[,13:32], 2, table)
colSums(apply(d[,13:32], 2, table))
dsave = d
d$major = as.character(d$major)
table(d$major)
d$major[d$major %in% stem]  = "stem"
d$major[d$major %in% stem]
stem  = c("a", "a. Eng", "a. Math", "a.Sci", "a. Sci", "a. Sci,Math",
"a. Sci, Tech", "a. Sc/Math", "a. Tech", "a. Tech,Eng",
"a. Tech,Math", "STEM")
med   = c("b", "c + b", "SCI: c, b & b", "SCI: c-b; b: ALL") # medical students
dual  = c("a. Sci & b", "b+a. Eng", "d", "STEM & b") # stem + non-stem
other = c("", " ", "c") # other students, includes blank responses
d$major[d$major %in% stem]
d$major[d$major %in% stem]  = "stem"
d$major[d$major %in% med]   = "med"
d$major[d$major %in% dual]  = "dual"
d$major[d$major %in% other] = "other"
table(d$major)
stem  = c("a", "a. Eng", "a. Math", "a.Sci", "a. Sci", "a. Sci,Math",
"a. Sci, Tech", "a. Sc/Math", "a. Tech", "a. Tech,Eng",
"a. Tech,Math", "STEM", "a. Sci,Tech", "MATH")
med   = c("b", "c + b", "SCI: c, b & b",
"SCI: c-b; b: ALL", "a. Sci+c")            # medical students
dual  = c("a. Sci & b", "b+a. Eng", "d", "STEM & b") # stem + non-stem
other = c("", " ", "c", "Other", "C")                # other students, blanks
# length(stem) + length(med) + length(dual) + length(other)
d$major = as.character(d$major)
d$major[d$major %in% stem]  = "stem"
d$major[d$major %in% med]   = "med"
d$major[d$major %in% dual]  = "dual"
d$major[d$major %in% other] = "other"
table(d$major)
d$major = as.factor(d$major)
str(d)
# remove letter variable
d$letter = NULL
str(d)
d$ethnic = as.factor(d$ethnic)
str(d)
# remove emp_on, emp_off variables
d$emp_off = NULL
d$emp_on  = NULL
str(d)
d = d %>% mutate(old_must = must - MQ6 - MQ16 - MQ17 - MQ18)
# create 5 category scores (see revision_notes.txt for details)
d = d %>% mutate(mult    = MQ1  +  MQ2  + MQ3,
div     = MQ4  +  MQ6  + MQ7  + MQ8  + MQ16,
frac    = MQ9  +  MQ10 + MQ17 + MQ18,
log_exp = MQ5  +  MQ12 + MQ13 + MQ14 + MQ15,
chem    = MQ11 +  MQ19 + MQ20)
dim9d
dim(d)
write.csv(d, "must.csv", row.names = FALSE)
test_read = read.csv("must.csv")
str(test_read)
str(d) # make sure all strings are saved as factors, keep must q's as numeric
# modeling.R
library(glmnet)
# setwd("~/ChemEd/revisions")              # linux machine path
setwd("C:/Users/chuu/ChemEd/revisions")    # windows machine path
# source("/home/eric/ChemEd/paper_2/misc.R")    # linux machine path to misc.R
source("C:/Users/chuu/ChemEd/paper_2/misc.R") # windows machine path to misc.R
x0 = read.csv("revised_x.csv")  # revised_x is the final cleaned data
# ensure that each question is encoded as a factor
indicator_vars = c("gender", "version", MUST_q)
MUST_q
